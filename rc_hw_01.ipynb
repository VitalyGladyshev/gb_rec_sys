{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 1\n",
    "\n",
    "## Задание 1\n",
    "\n",
    "Сравните метрики hit_rate@k, precision@k. Какую матрику использовать предпочтительно и почему. Привидите пример 2-3 задач (опишите, что является клиентом, что товаром), в которой более уместно использовать метрику hit_rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ\n",
    "\n",
    "hit_rate@k - это наличие хотя бы одного релевантного товара из k рекомендованных. <br>precision@k - это доля релевантных товаров из k рекомендованных. \n",
    "- Если у нас потоковые рекомендации, например треки в плейлисте или товары массового потребления на Ozon, то нас интересует доля, т.е. precision@k\n",
    "- Если мы рекомендуме товар штучного спроса, квартиры, машины, курсы на GB :), то нас интересует сам факт интереса потенциального клиента к данной категории товаров, т.е. hit_rate@k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "В метрике NDCG@k мы используем логарифм в знаменателе. Как Вы думаете, почему именно логарифм? Какую функцию можно использовать вместо логарифма? Привидите пример метрик/подходов к предобработке данных/функций ошибок в ML, где также в знаменателе присутствует логарифм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ\n",
    "\n",
    "Логарифм даёт \"сглаживание\". В контексте NDCG@k даёт меньший штраф при ошибке ранжирования. Наряду с логарифмом можно использовать сигмоид, возможно гиперболический тангенс. Логарифм в функции потерь даёт удобство дифференцирования. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Какие еще метрики (Вы можете вспомнить уже пройденные Вами или посмотреть в интернете) могут использоваться для рекомендательных систем (приведите примеры метрики и чем являются интеракции, чтобы она могла быть использована)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ\n",
    "\n",
    "#### Непрерывные метрики:\n",
    "Оценка подобия клиентов или таргетов (товаров, треков в плейлисте и т.д.). При пересчёте взаимодействия в валовые единицы (денежные или объёмные единицы измерения). \n",
    "- MAE (Mean Absolute Error) Среднее абсолютное отклонение\n",
    "- MSE (Mean Squared Error) Среднеквадратичная ошибка\n",
    "- RMSE (Root Mean Squared Error) Корень из среднеквадратичной ошибки\n",
    "\n",
    "#### Дискретные метрики:\n",
    "Используются при учёте дискретных взаимодействий типа: клиент-товар, товар-товар, товар-клиент (обращение клиета к карточкам и разделам каталога, приобретение товара):\n",
    "- Precision Доля рекомендаций, понравившихся пользователю\n",
    "- Recall Доля интересных пользователю товаров, которая показана\n",
    "- F1-Measure Среднее гармоническое метрик Precision и Recall. Полезно, когда заранее невозможно сказать, какая из метрик важнее\n",
    "- ROC AUC Насколько высока концентрация интересных товаров в начале списка рекомендаций\n",
    "- Precision@N Метрика Precision, посчитанная на Top-N записях\n",
    "- Recall@N Метрика Recall, посчитанная на Top-N записях\n",
    "- AverageP Среднее значение Precision на всем списке рекомендаций\n",
    "\n",
    "#### Метрики ранжирования (Rank Accuracy):\n",
    "Необходимы при оценки релевантности в зависимости от позиции\n",
    "- Mean Reciprocal Rank На какой позиции списка рекомендаций пользователь находит первую полезную\n",
    "- Spearman Correlation Корреляция (Спирмена) реального и прогнозируемого рангов рекомендаций\n",
    "- nDCG Информативность выдачи с учетом ранжирования рекомендаций\n",
    "- Fraction of Concordance Pairs Насколько высока концентрация интересных товаров в начале списка рекомендаций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boughted = [1, 3, 5, 7, 9, 11]\n",
    "recommended = [2, 5, 7, 4, 11, 9, 8, 10, 12, 3]\n",
    "k = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте на этих данных pr@8, rec@8, AP@8, NDCG@8, RR@8, ERR@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pr@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended_list, bought_list, k=5):\n",
    "    \n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)\n",
    "    \n",
    "    bought_list = bought_list  # Тут нет [:k] !!\n",
    "    recommended_list = recommended_list[:k]\n",
    "    \n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "    print(flags)\n",
    "    \n",
    "    precision = flags.sum() / len(recommended_list)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(recommended, boughted, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rec@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended_list, bought_list, k=5):\n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)[:k]\n",
    "    \n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "    \n",
    "    recall = flags.sum() / len(bought_list)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(recommended, boughted, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_at_k(recommended_list, bought_list, k=5):\n",
    "    \n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)\n",
    "    \n",
    "    flags = np.isin(recommended_list, bought_list)\n",
    "    \n",
    "    if sum(flags) == 0:\n",
    "        return 0\n",
    "    \n",
    "    sum_ = 0\n",
    "    for i in range(1, k+1): \n",
    "        if flags[i] == True:\n",
    "            p_k = precision_at_k(recommended_list, bought_list, k=i)\n",
    "            sum_ += p_k\n",
    "            \n",
    "    result = sum_ / sum(flags)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False]\n",
      "[False False  True False False False]\n",
      "[False False  True  True False False]\n",
      "[False False  True  True False  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_at_k(recommended, boughted, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RR@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_at_k(recommended_list, bought_list, k=8):\n",
    "    ranks=0.\n",
    "    for item_rec in recommended_list[:k]:\n",
    "        for i, item_bought in enumerate(bought_list):\n",
    "            if item_rec == item_bought:\n",
    "                ranks += 1 / (i+1)\n",
    "    return ranks / len(recommended_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.095"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reciprocal_rank_at_k(recommended, boughted, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERR@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
